{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17290d26",
   "metadata": {},
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb5137",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616083a",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8429d1",
   "metadata": {},
   "source": [
    "#### The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1071cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5e433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a273080",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df16a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.391</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>10</td>\n",
       "      <td>161</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "      <td>132</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.326</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>105</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.268</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.647</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>46</td>\n",
       "      <td>145</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.284</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "76                7                      62              78               0   \n",
       "306              10                     161              68              23   \n",
       "515               3                     163              70              18   \n",
       "134               2                      96              68              13   \n",
       "428               0                     135              94              46   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "76         0  32.6              0.391   41             0  \n",
       "306      132  25.5              0.326   47             1  \n",
       "515      105  31.6              0.268   28             1  \n",
       "134       49  21.1              0.647   26             0  \n",
       "428      145  40.6              0.284   26             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b25a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values #Input values\n",
    "y = diabetes_df[\"has_diabetes\"].values # Target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41346e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366e67d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eacb9a2",
   "metadata": {},
   "source": [
    "- Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  \n",
    "- This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. \n",
    "- We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6629c68f",
   "metadata": {},
   "source": [
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f448a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8529451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.714\n",
      "Roc-Auc is: 0.802\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print(f\"Accuracy is: {accuracy_score(y_test, y_pred_class_rf):.3f}\")\n",
    "print(f\"Roc-Auc is: {roc_auc_score(y_test, y_pred_prob_rf[:, 1]):.3f}\") # We just the positive classes probabilites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d62d444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title=f\"ROC Curve for {model_name} on PIMA diabetes problem.\",\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a945e",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "- We will use the **Sequential model** to quickly build a neural network.\n",
    "- Our first network will be a **single layer network**.  \n",
    "- We have 8 variables, so we set the input shape to 8.  \n",
    "- Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f76a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f133cb",
   "metadata": {},
   "source": [
    "- Define the Model \n",
    "- Input size is 8-dimensional\n",
    "- 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "- Final layer has just one node with a **sigmoid activation (standard for binary classification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74cb56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(tf.keras.layers.Dense(12, input_shape=(8,), activation=\"sigmoid\"))\n",
    "model_1.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3aa0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ddca9",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "- Why do we have 121 parameters?\n",
    "    - We have 108 params in the first layer because: We have 8 input values in the Dense layer + a bias term = 9 values and we have 12 units in that layer. <br> So 12 x 9 = 108 params. \n",
    "    - Then to get to the next layer, again, you're going from 12 down to one, so it's going to be fully connected to that one plus the bias term so you have 12 plus that one, and that's going to be equal to 13,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a186fc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0143 - accuracy: 0.3455 - val_loss: 0.9694 - val_accuracy: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9780 - accuracy: 0.3455 - val_loss: 0.9364 - val_accuracy: 0.3594\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9446 - accuracy: 0.3455 - val_loss: 0.9062 - val_accuracy: 0.3594\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9141 - accuracy: 0.3455 - val_loss: 0.8787 - val_accuracy: 0.3594\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8862 - accuracy: 0.3455 - val_loss: 0.8535 - val_accuracy: 0.3542\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8607 - accuracy: 0.3455 - val_loss: 0.8307 - val_accuracy: 0.3542\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8376 - accuracy: 0.3455 - val_loss: 0.8101 - val_accuracy: 0.3542\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8166 - accuracy: 0.3490 - val_loss: 0.7914 - val_accuracy: 0.3542\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7975 - accuracy: 0.3490 - val_loss: 0.7744 - val_accuracy: 0.3542\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7803 - accuracy: 0.3472 - val_loss: 0.7592 - val_accuracy: 0.3594\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7647 - accuracy: 0.3420 - val_loss: 0.7454 - val_accuracy: 0.3646\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7506 - accuracy: 0.3559 - val_loss: 0.7329 - val_accuracy: 0.3750\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7378 - accuracy: 0.3611 - val_loss: 0.7217 - val_accuracy: 0.4115\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7262 - accuracy: 0.3941 - val_loss: 0.7116 - val_accuracy: 0.4167\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7157 - accuracy: 0.4236 - val_loss: 0.7024 - val_accuracy: 0.4271\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.4635 - val_loss: 0.6942 - val_accuracy: 0.4844\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.4983 - val_loss: 0.6868 - val_accuracy: 0.5417\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5417 - val_loss: 0.6801 - val_accuracy: 0.5885\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5781 - val_loss: 0.6740 - val_accuracy: 0.5990\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6059 - val_loss: 0.6685 - val_accuracy: 0.6198\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.6233 - val_loss: 0.6635 - val_accuracy: 0.6146\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.6424 - val_loss: 0.6590 - val_accuracy: 0.6198\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6580 - val_loss: 0.6550 - val_accuracy: 0.6510\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6684 - val_loss: 0.6512 - val_accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6649 - val_loss: 0.6478 - val_accuracy: 0.6823\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6736 - val_loss: 0.6447 - val_accuracy: 0.6823\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6736 - val_loss: 0.6419 - val_accuracy: 0.6927\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6892 - val_loss: 0.6393 - val_accuracy: 0.7083\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.6840 - val_loss: 0.6369 - val_accuracy: 0.7240\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6806 - val_loss: 0.6347 - val_accuracy: 0.7344\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6771 - val_loss: 0.6326 - val_accuracy: 0.7292\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6771 - val_loss: 0.6307 - val_accuracy: 0.7188\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6806 - val_loss: 0.6289 - val_accuracy: 0.7188\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6806 - val_loss: 0.6273 - val_accuracy: 0.7188\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6736 - val_loss: 0.6258 - val_accuracy: 0.7240\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6736 - val_loss: 0.6243 - val_accuracy: 0.7188\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6753 - val_loss: 0.6230 - val_accuracy: 0.7135\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6788 - val_loss: 0.6217 - val_accuracy: 0.7083\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6771 - val_loss: 0.6205 - val_accuracy: 0.7083\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6788 - val_loss: 0.6194 - val_accuracy: 0.7083\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.6806 - val_loss: 0.6183 - val_accuracy: 0.7031\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6788 - val_loss: 0.6172 - val_accuracy: 0.6979\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6771 - val_loss: 0.6163 - val_accuracy: 0.6979\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.6788 - val_loss: 0.6153 - val_accuracy: 0.7031\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6736 - val_loss: 0.6144 - val_accuracy: 0.6979\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6719 - val_loss: 0.6135 - val_accuracy: 0.6979\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6736 - val_loss: 0.6127 - val_accuracy: 0.7031\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6719 - val_loss: 0.6119 - val_accuracy: 0.7031\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6719 - val_loss: 0.6111 - val_accuracy: 0.7031\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6701 - val_loss: 0.6103 - val_accuracy: 0.6979\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6719 - val_loss: 0.6095 - val_accuracy: 0.6927\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6701 - val_loss: 0.6088 - val_accuracy: 0.6875\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6719 - val_loss: 0.6081 - val_accuracy: 0.6875\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6701 - val_loss: 0.6074 - val_accuracy: 0.6875\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.6753 - val_loss: 0.6067 - val_accuracy: 0.6875\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6753 - val_loss: 0.6060 - val_accuracy: 0.6875\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6736 - val_loss: 0.6053 - val_accuracy: 0.6823\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6719 - val_loss: 0.6047 - val_accuracy: 0.6823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6719 - val_loss: 0.6040 - val_accuracy: 0.6823\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.6719 - val_loss: 0.6034 - val_accuracy: 0.6823\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6719 - val_loss: 0.6028 - val_accuracy: 0.6823\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6736 - val_loss: 0.6021 - val_accuracy: 0.6823\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.6736 - val_loss: 0.6015 - val_accuracy: 0.6823\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6736 - val_loss: 0.6009 - val_accuracy: 0.6823\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6736 - val_loss: 0.6003 - val_accuracy: 0.6823\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6736 - val_loss: 0.5997 - val_accuracy: 0.6823\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6736 - val_loss: 0.5991 - val_accuracy: 0.6823\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6736 - val_loss: 0.5985 - val_accuracy: 0.6823\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6719 - val_loss: 0.5980 - val_accuracy: 0.6823\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6719 - val_loss: 0.5974 - val_accuracy: 0.6823\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6736 - val_loss: 0.5968 - val_accuracy: 0.6823\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6736 - val_loss: 0.5962 - val_accuracy: 0.6823\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6736 - val_loss: 0.5957 - val_accuracy: 0.6823\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6736 - val_loss: 0.5951 - val_accuracy: 0.6771\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6788 - val_loss: 0.5946 - val_accuracy: 0.6771\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.6806 - val_loss: 0.5940 - val_accuracy: 0.6771\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.6806 - val_loss: 0.5935 - val_accuracy: 0.6771\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.6806 - val_loss: 0.5929 - val_accuracy: 0.6771\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6806 - val_loss: 0.5924 - val_accuracy: 0.6771\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.6788 - val_loss: 0.5918 - val_accuracy: 0.6771\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.6806 - val_loss: 0.5913 - val_accuracy: 0.6771\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6806 - val_loss: 0.5908 - val_accuracy: 0.6771\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6823 - val_loss: 0.5902 - val_accuracy: 0.6771\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6840 - val_loss: 0.5897 - val_accuracy: 0.6771\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6840 - val_loss: 0.5892 - val_accuracy: 0.6771\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.6875 - val_loss: 0.5887 - val_accuracy: 0.6771\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.6840 - val_loss: 0.5881 - val_accuracy: 0.6771\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.6858 - val_loss: 0.5876 - val_accuracy: 0.6771\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.6875 - val_loss: 0.5871 - val_accuracy: 0.6771\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.6892 - val_loss: 0.5866 - val_accuracy: 0.6771\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.6892 - val_loss: 0.5861 - val_accuracy: 0.6771\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.6892 - val_loss: 0.5856 - val_accuracy: 0.6771\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6892 - val_loss: 0.5851 - val_accuracy: 0.6771\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.6927 - val_loss: 0.5846 - val_accuracy: 0.6771\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.6927 - val_loss: 0.5841 - val_accuracy: 0.6771\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6927 - val_loss: 0.5836 - val_accuracy: 0.6875\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.6927 - val_loss: 0.5831 - val_accuracy: 0.6875\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.6927 - val_loss: 0.5826 - val_accuracy: 0.6927\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.6927 - val_loss: 0.5821 - val_accuracy: 0.7031\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.6944 - val_loss: 0.5817 - val_accuracy: 0.7031\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.6944 - val_loss: 0.5812 - val_accuracy: 0.7031\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.6944 - val_loss: 0.5807 - val_accuracy: 0.7031\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.6944 - val_loss: 0.5802 - val_accuracy: 0.7031\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.6927 - val_loss: 0.5797 - val_accuracy: 0.7031\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.6944 - val_loss: 0.5793 - val_accuracy: 0.7031\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.6944 - val_loss: 0.5788 - val_accuracy: 0.7031\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.6962 - val_loss: 0.5783 - val_accuracy: 0.7031\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.6979 - val_loss: 0.5779 - val_accuracy: 0.7083\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.6979 - val_loss: 0.5774 - val_accuracy: 0.7083\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.6997 - val_loss: 0.5769 - val_accuracy: 0.7135\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.6979 - val_loss: 0.5765 - val_accuracy: 0.7135\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.6997 - val_loss: 0.5760 - val_accuracy: 0.7135\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.6997 - val_loss: 0.5756 - val_accuracy: 0.7135\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7014 - val_loss: 0.5751 - val_accuracy: 0.7135\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7014 - val_loss: 0.5747 - val_accuracy: 0.7135\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.6979 - val_loss: 0.5742 - val_accuracy: 0.7135\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.6997 - val_loss: 0.5738 - val_accuracy: 0.7135\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.6979 - val_loss: 0.5734 - val_accuracy: 0.7135\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.6979 - val_loss: 0.5729 - val_accuracy: 0.7135\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.6997 - val_loss: 0.5725 - val_accuracy: 0.7135\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.6997 - val_loss: 0.5720 - val_accuracy: 0.7135\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.6997 - val_loss: 0.5716 - val_accuracy: 0.7135\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.5712 - val_accuracy: 0.7135\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.5708 - val_accuracy: 0.7188\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7014 - val_loss: 0.5703 - val_accuracy: 0.7188\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.6997 - val_loss: 0.5699 - val_accuracy: 0.7240\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7014 - val_loss: 0.5695 - val_accuracy: 0.7240\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7031 - val_loss: 0.5691 - val_accuracy: 0.7292\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7031 - val_loss: 0.5687 - val_accuracy: 0.7292\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7031 - val_loss: 0.5683 - val_accuracy: 0.7240\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7031 - val_loss: 0.5678 - val_accuracy: 0.7240\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7031 - val_loss: 0.5674 - val_accuracy: 0.7240\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7031 - val_loss: 0.5670 - val_accuracy: 0.7240\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7049 - val_loss: 0.5666 - val_accuracy: 0.7292\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7049 - val_loss: 0.5662 - val_accuracy: 0.7292\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7049 - val_loss: 0.5658 - val_accuracy: 0.7292\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7101 - val_loss: 0.5654 - val_accuracy: 0.7292\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7101 - val_loss: 0.5650 - val_accuracy: 0.7292\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7101 - val_loss: 0.5646 - val_accuracy: 0.7292\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7118 - val_loss: 0.5642 - val_accuracy: 0.7292\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7118 - val_loss: 0.5639 - val_accuracy: 0.7292\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7118 - val_loss: 0.5635 - val_accuracy: 0.7344\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7135 - val_loss: 0.5631 - val_accuracy: 0.7292\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7135 - val_loss: 0.5627 - val_accuracy: 0.7292\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7135 - val_loss: 0.5623 - val_accuracy: 0.7396\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7135 - val_loss: 0.5619 - val_accuracy: 0.7396\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7170 - val_loss: 0.5616 - val_accuracy: 0.7344\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7135 - val_loss: 0.5612 - val_accuracy: 0.7344\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7170 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7153 - val_loss: 0.5605 - val_accuracy: 0.7344\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7153 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7153 - val_loss: 0.5597 - val_accuracy: 0.7344\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7188 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7188 - val_loss: 0.5590 - val_accuracy: 0.7396\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7205 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7205 - val_loss: 0.5583 - val_accuracy: 0.7396\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7240 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7257 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7240 - val_loss: 0.5572 - val_accuracy: 0.7344\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7292 - val_loss: 0.5569 - val_accuracy: 0.7344\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7292 - val_loss: 0.5565 - val_accuracy: 0.7344\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7326 - val_loss: 0.5562 - val_accuracy: 0.7344\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7326 - val_loss: 0.5559 - val_accuracy: 0.7344\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7344 - val_loss: 0.5555 - val_accuracy: 0.7344\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7326 - val_loss: 0.5552 - val_accuracy: 0.7292\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7344 - val_loss: 0.5548 - val_accuracy: 0.7292\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7361 - val_loss: 0.5545 - val_accuracy: 0.7292\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7361 - val_loss: 0.5542 - val_accuracy: 0.7292\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7344 - val_loss: 0.5538 - val_accuracy: 0.7292\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7344 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7361 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7378 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7396 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7396 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7396 - val_loss: 0.5519 - val_accuracy: 0.7292\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7396 - val_loss: 0.5516 - val_accuracy: 0.7292\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7396 - val_loss: 0.5513 - val_accuracy: 0.7292\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7413 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7448 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7413 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7413 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7413 - val_loss: 0.5497 - val_accuracy: 0.7344\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7413 - val_loss: 0.5494 - val_accuracy: 0.7344\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7413 - val_loss: 0.5491 - val_accuracy: 0.7344\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7413 - val_loss: 0.5488 - val_accuracy: 0.7344\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7413 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7413 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7413 - val_loss: 0.5479 - val_accuracy: 0.7396\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7413 - val_loss: 0.5476 - val_accuracy: 0.7396\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7431 - val_loss: 0.5473 - val_accuracy: 0.7396\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7448 - val_loss: 0.5470 - val_accuracy: 0.7396\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7431 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7431 - val_loss: 0.5465 - val_accuracy: 0.7396\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7448 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7448 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7448 - val_loss: 0.5456 - val_accuracy: 0.7344\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7448 - val_loss: 0.5453 - val_accuracy: 0.7344\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7448 - val_loss: 0.5450 - val_accuracy: 0.7344\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7431 - val_loss: 0.5448 - val_accuracy: 0.7344\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7448 - val_loss: 0.5445 - val_accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.003)\n",
    "model_1.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, \n",
    "                         validation_data=(X_test_norm, y_test), epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b808512",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a31aa95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25b92fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34568253],\n",
       "       [0.22897029],\n",
       "       [0.26541758],\n",
       "       [0.38674912],\n",
       "       [0.47082052],\n",
       "       [0.4123608 ],\n",
       "       [0.13933143],\n",
       "       [0.38799557],\n",
       "       [0.42226028],\n",
       "       [0.51163906]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd1e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.734\n",
      "Roc-Auc is: 0.801\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print(f\"Accuracy is: {accuracy_score(y_test, y_pred_class_nn_1):.3f}\")\n",
    "print(f\"Roc-Auc is: {roc_auc_score(y_test, y_pred_prob_nn_1):.3f}\")\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b8fe5",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d72ac620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39696ce4",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c61a422b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2431877de20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"], \"r\", marker=\".\", label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"], \"b\", marker=\".\", label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95dc4e",
   "metadata": {},
   "source": [
    "- Looks like the losses are still going down on both the training set and the validation set.\n",
    "- This suggests that the model might benefit from further training.\n",
    "- Let's train the model a little more and see what happens.\n",
    "- Note that **it will pick up from where it left off.** \n",
    "- Train for 600 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b188318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7448 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
      "Epoch 2/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7448 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
      "Epoch 3/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7448 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
      "Epoch 4/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7448 - val_loss: 0.5434 - val_accuracy: 0.7396\n",
      "Epoch 5/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7448 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
      "Epoch 6/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7465 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
      "Epoch 7/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7483 - val_loss: 0.5426 - val_accuracy: 0.7396\n",
      "Epoch 8/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7500 - val_loss: 0.5424 - val_accuracy: 0.7396\n",
      "Epoch 9/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7500 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
      "Epoch 10/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7500 - val_loss: 0.5418 - val_accuracy: 0.7396\n",
      "Epoch 11/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7500 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
      "Epoch 12/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7483 - val_loss: 0.5413 - val_accuracy: 0.7396\n",
      "Epoch 13/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7465 - val_loss: 0.5411 - val_accuracy: 0.7396\n",
      "Epoch 14/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7465 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
      "Epoch 15/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7465 - val_loss: 0.5406 - val_accuracy: 0.7448\n",
      "Epoch 16/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7465 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 17/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7465 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
      "Epoch 18/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7465 - val_loss: 0.5398 - val_accuracy: 0.7448\n",
      "Epoch 19/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7465 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 20/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7448 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 21/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7465 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 22/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7465 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 23/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7465 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
      "Epoch 24/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7448 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 25/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7465 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 26/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7483 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
      "Epoch 27/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7483 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
      "Epoch 28/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7483 - val_loss: 0.5375 - val_accuracy: 0.7500\n",
      "Epoch 29/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7517 - val_loss: 0.5372 - val_accuracy: 0.7500\n",
      "Epoch 30/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7535 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
      "Epoch 31/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7517 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
      "Epoch 32/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7535 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
      "Epoch 33/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7535 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
      "Epoch 34/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7552 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
      "Epoch 35/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7552 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
      "Epoch 36/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7535 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
      "Epoch 37/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7535 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
      "Epoch 38/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7535 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
      "Epoch 39/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7517 - val_loss: 0.5350 - val_accuracy: 0.7552\n",
      "Epoch 40/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7552 - val_loss: 0.5348 - val_accuracy: 0.7552\n",
      "Epoch 41/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7552 - val_loss: 0.5346 - val_accuracy: 0.7552\n",
      "Epoch 42/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7552 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
      "Epoch 43/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7552 - val_loss: 0.5342 - val_accuracy: 0.7552\n",
      "Epoch 44/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7535 - val_loss: 0.5340 - val_accuracy: 0.7552\n",
      "Epoch 45/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7535 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
      "Epoch 46/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7517 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
      "Epoch 47/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7500 - val_loss: 0.5333 - val_accuracy: 0.7552\n",
      "Epoch 48/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7500 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
      "Epoch 49/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7500 - val_loss: 0.5329 - val_accuracy: 0.7552\n",
      "Epoch 50/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7517 - val_loss: 0.5327 - val_accuracy: 0.7552\n",
      "Epoch 51/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7517 - val_loss: 0.5325 - val_accuracy: 0.7552\n",
      "Epoch 52/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7517 - val_loss: 0.5323 - val_accuracy: 0.7552\n",
      "Epoch 53/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7517 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
      "Epoch 54/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7500 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
      "Epoch 55/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7500 - val_loss: 0.5317 - val_accuracy: 0.7552\n",
      "Epoch 56/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7500 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 57/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7500 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 58/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7500 - val_loss: 0.5312 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7500 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 60/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7500 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
      "Epoch 61/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7483 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
      "Epoch 62/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7500 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 63/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7483 - val_loss: 0.5302 - val_accuracy: 0.7552\n",
      "Epoch 64/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7483 - val_loss: 0.5301 - val_accuracy: 0.7552\n",
      "Epoch 65/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7483 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 66/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7500 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 67/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7517 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 68/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7517 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 69/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7517 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 70/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7552 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 71/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7535 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 72/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7552 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 73/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7552 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 74/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7552 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 75/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7552 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 76/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7535 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 77/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7552 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 78/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7552 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 79/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7552 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 80/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7569 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 81/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7587 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 82/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7569 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 83/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7604 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 84/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7587 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 85/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7587 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 86/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7587 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 87/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7587 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 88/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7587 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
      "Epoch 89/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7587 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
      "Epoch 90/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7587 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
      "Epoch 91/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7587 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
      "Epoch 92/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7604 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
      "Epoch 93/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7604 - val_loss: 0.5252 - val_accuracy: 0.7604\n",
      "Epoch 94/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7604 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
      "Epoch 95/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7587 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
      "Epoch 96/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7604 - val_loss: 0.5248 - val_accuracy: 0.7656\n",
      "Epoch 97/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7587 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
      "Epoch 98/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7604 - val_loss: 0.5245 - val_accuracy: 0.7656\n",
      "Epoch 99/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7604 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
      "Epoch 100/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7604 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 101/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
      "Epoch 102/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7604 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
      "Epoch 103/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7604 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 104/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7587 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
      "Epoch 105/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7587 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 106/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7569 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
      "Epoch 107/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7587 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
      "Epoch 108/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7569 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
      "Epoch 109/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7587 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
      "Epoch 110/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7587 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
      "Epoch 111/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7587 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
      "Epoch 112/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7587 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
      "Epoch 113/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7587 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
      "Epoch 114/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7587 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
      "Epoch 115/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7587 - val_loss: 0.5222 - val_accuracy: 0.7656\n",
      "Epoch 116/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
      "Epoch 117/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
      "Epoch 118/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
      "Epoch 119/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7587 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
      "Epoch 120/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7587 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
      "Epoch 121/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7587 - val_loss: 0.5214 - val_accuracy: 0.7656\n",
      "Epoch 122/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7587 - val_loss: 0.5213 - val_accuracy: 0.7656\n",
      "Epoch 123/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
      "Epoch 124/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7587 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
      "Epoch 125/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7587 - val_loss: 0.5209 - val_accuracy: 0.7656\n",
      "Epoch 126/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7587 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
      "Epoch 127/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7587 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
      "Epoch 128/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7587 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
      "Epoch 129/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7587 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
      "Epoch 130/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7587 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
      "Epoch 131/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7587 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
      "Epoch 132/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7587 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
      "Epoch 133/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7587 - val_loss: 0.5200 - val_accuracy: 0.7708\n",
      "Epoch 134/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7587 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
      "Epoch 135/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7622 - val_loss: 0.5198 - val_accuracy: 0.7708\n",
      "Epoch 136/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7639 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
      "Epoch 137/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7639 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
      "Epoch 138/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7622 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
      "Epoch 139/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7639 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
      "Epoch 140/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7639 - val_loss: 0.5192 - val_accuracy: 0.7708\n",
      "Epoch 141/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7622 - val_loss: 0.5191 - val_accuracy: 0.7708\n",
      "Epoch 142/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7639 - val_loss: 0.5190 - val_accuracy: 0.7708\n",
      "Epoch 143/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7639 - val_loss: 0.5189 - val_accuracy: 0.7708\n",
      "Epoch 144/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7639 - val_loss: 0.5188 - val_accuracy: 0.7708\n",
      "Epoch 145/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7622 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
      "Epoch 146/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7639 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
      "Epoch 147/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7656 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
      "Epoch 148/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7674 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
      "Epoch 149/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7639 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
      "Epoch 150/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7674 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
      "Epoch 151/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
      "Epoch 152/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7674 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
      "Epoch 153/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7674 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
      "Epoch 154/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7674 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
      "Epoch 155/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7674 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
      "Epoch 156/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7674 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
      "Epoch 157/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7691 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
      "Epoch 158/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7691 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 159/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7691 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
      "Epoch 160/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7691 - val_loss: 0.5172 - val_accuracy: 0.7604\n",
      "Epoch 161/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7691 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
      "Epoch 162/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7691 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 163/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7691 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 164/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7691 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
      "Epoch 165/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7691 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
      "Epoch 166/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7691 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
      "Epoch 167/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7691 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
      "Epoch 168/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7691 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
      "Epoch 169/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7691 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
      "Epoch 170/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7691 - val_loss: 0.5163 - val_accuracy: 0.7604\n",
      "Epoch 171/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7691 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
      "Epoch 172/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7708 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
      "Epoch 173/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7691 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 174/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7691 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 175/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7708 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 176/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7708 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 177/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7708 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 178/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7708 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 179/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7708 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 180/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7708 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 181/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7708 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 182/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7708 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
      "Epoch 183/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7708 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
      "Epoch 184/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7708 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 185/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7708 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 186/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7708 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 187/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7708 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 188/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7708 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
      "Epoch 189/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7708 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 190/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7708 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 191/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7708 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
      "Epoch 192/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7708 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
      "Epoch 193/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7708 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
      "Epoch 194/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7708 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
      "Epoch 195/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7708 - val_loss: 0.5143 - val_accuracy: 0.7760\n",
      "Epoch 196/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7708 - val_loss: 0.5142 - val_accuracy: 0.7760\n",
      "Epoch 197/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7708 - val_loss: 0.5142 - val_accuracy: 0.7760\n",
      "Epoch 198/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7708 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
      "Epoch 199/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7708 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
      "Epoch 200/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7708 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
      "Epoch 201/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7708 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
      "Epoch 202/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7708 - val_loss: 0.5138 - val_accuracy: 0.7812\n",
      "Epoch 203/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7708 - val_loss: 0.5137 - val_accuracy: 0.7812\n",
      "Epoch 204/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7708 - val_loss: 0.5137 - val_accuracy: 0.7812\n",
      "Epoch 205/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7726 - val_loss: 0.5136 - val_accuracy: 0.7812\n",
      "Epoch 206/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7812\n",
      "Epoch 207/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7812\n",
      "Epoch 208/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7726 - val_loss: 0.5134 - val_accuracy: 0.7812\n",
      "Epoch 209/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7726 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
      "Epoch 210/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7726 - val_loss: 0.5133 - val_accuracy: 0.7812\n",
      "Epoch 211/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7812\n",
      "Epoch 212/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7812\n",
      "Epoch 213/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7812\n",
      "Epoch 214/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7743 - val_loss: 0.5130 - val_accuracy: 0.7812\n",
      "Epoch 215/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7743 - val_loss: 0.5129 - val_accuracy: 0.7812\n",
      "Epoch 216/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7812\n",
      "Epoch 217/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7812\n",
      "Epoch 218/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7812\n",
      "Epoch 219/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
      "Epoch 220/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7726 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
      "Epoch 221/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
      "Epoch 222/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.5125 - val_accuracy: 0.7812\n",
      "Epoch 223/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7743 - val_loss: 0.5125 - val_accuracy: 0.7812\n",
      "Epoch 224/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7812\n",
      "Epoch 225/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7812\n",
      "Epoch 226/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7812\n",
      "Epoch 227/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7743 - val_loss: 0.5122 - val_accuracy: 0.7812\n",
      "Epoch 228/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7760 - val_loss: 0.5122 - val_accuracy: 0.7812\n",
      "Epoch 229/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7760 - val_loss: 0.5121 - val_accuracy: 0.7812\n",
      "Epoch 230/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7760 - val_loss: 0.5121 - val_accuracy: 0.7812\n",
      "Epoch 231/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7726 - val_loss: 0.5120 - val_accuracy: 0.7812\n",
      "Epoch 232/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7760 - val_loss: 0.5119 - val_accuracy: 0.7812\n",
      "Epoch 233/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7743 - val_loss: 0.5119 - val_accuracy: 0.7812\n",
      "Epoch 234/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7760 - val_loss: 0.5118 - val_accuracy: 0.7812\n",
      "Epoch 235/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7743 - val_loss: 0.5118 - val_accuracy: 0.7812\n",
      "Epoch 236/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7743 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 237/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7743 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
      "Epoch 238/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7743 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
      "Epoch 239/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7743 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
      "Epoch 240/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7743 - val_loss: 0.5115 - val_accuracy: 0.7760\n",
      "Epoch 241/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7743 - val_loss: 0.5115 - val_accuracy: 0.7760\n",
      "Epoch 242/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7743 - val_loss: 0.5114 - val_accuracy: 0.7760\n",
      "Epoch 243/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7743 - val_loss: 0.5114 - val_accuracy: 0.7760\n",
      "Epoch 244/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7743 - val_loss: 0.5113 - val_accuracy: 0.7760\n",
      "Epoch 245/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7743 - val_loss: 0.5113 - val_accuracy: 0.7760\n",
      "Epoch 246/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7743 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 247/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 248/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7743 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 249/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 250/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7743 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 251/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 252/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
      "Epoch 253/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
      "Epoch 254/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7760\n",
      "Epoch 255/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7760\n",
      "Epoch 256/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7760\n",
      "Epoch 257/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7760\n",
      "Epoch 258/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.7760\n",
      "Epoch 259/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.7760\n",
      "Epoch 260/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.7760\n",
      "Epoch 261/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
      "Epoch 262/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7743 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
      "Epoch 263/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7743 - val_loss: 0.5104 - val_accuracy: 0.7760\n",
      "Epoch 264/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7743 - val_loss: 0.5104 - val_accuracy: 0.7760\n",
      "Epoch 265/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7743 - val_loss: 0.5103 - val_accuracy: 0.7760\n",
      "Epoch 266/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7743 - val_loss: 0.5103 - val_accuracy: 0.7760\n",
      "Epoch 267/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7743 - val_loss: 0.5102 - val_accuracy: 0.7760\n",
      "Epoch 268/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7743 - val_loss: 0.5102 - val_accuracy: 0.7760\n",
      "Epoch 269/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7743 - val_loss: 0.5102 - val_accuracy: 0.7760\n",
      "Epoch 270/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7743 - val_loss: 0.5101 - val_accuracy: 0.7760\n",
      "Epoch 271/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7743 - val_loss: 0.5101 - val_accuracy: 0.7760\n",
      "Epoch 272/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7743 - val_loss: 0.5100 - val_accuracy: 0.7760\n",
      "Epoch 273/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.5100 - val_accuracy: 0.7760\n",
      "Epoch 274/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.5100 - val_accuracy: 0.7760\n",
      "Epoch 275/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
      "Epoch 276/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
      "Epoch 277/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7743 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
      "Epoch 278/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
      "Epoch 279/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
      "Epoch 280/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
      "Epoch 281/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
      "Epoch 282/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7743 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
      "Epoch 283/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.5096 - val_accuracy: 0.7760\n",
      "Epoch 284/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.5096 - val_accuracy: 0.7760\n",
      "Epoch 285/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
      "Epoch 286/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7743 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
      "Epoch 287/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7743 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
      "Epoch 288/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
      "Epoch 289/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7743 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
      "Epoch 290/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7743 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
      "Epoch 291/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7743 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
      "Epoch 292/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7743 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
      "Epoch 293/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
      "Epoch 294/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7743 - val_loss: 0.5092 - val_accuracy: 0.7760\n",
      "Epoch 295/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7743 - val_loss: 0.5092 - val_accuracy: 0.7760\n",
      "Epoch 296/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7743 - val_loss: 0.5092 - val_accuracy: 0.7760\n",
      "Epoch 297/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7760\n",
      "Epoch 298/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7760\n",
      "Epoch 299/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 300/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 301/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 302/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 303/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
      "Epoch 304/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
      "Epoch 305/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
      "Epoch 306/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 307/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 308/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7743 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 309/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 310/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7743 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 311/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 312/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7743 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 313/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7743 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 314/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7743 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 315/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7743 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 316/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7743 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 317/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7743 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 318/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7743 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 319/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 320/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7743 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 321/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7743 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 322/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7743 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 323/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7743 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 324/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7743 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 325/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 326/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 327/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7743 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 328/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7743 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 329/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7743 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 330/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7743 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 331/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7743 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 332/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 333/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 334/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 335/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 336/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 337/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 338/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 339/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 340/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 341/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 342/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 343/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 344/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 345/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7743 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 346/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7743 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 347/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7760 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 348/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7760 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 349/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7760 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 350/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 351/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 352/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 353/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 354/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 355/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 356/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 357/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 358/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 359/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 360/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 361/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 362/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 363/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 364/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 365/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 366/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 367/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 368/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 369/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 370/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 371/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 372/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 373/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 374/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 375/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 376/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 377/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 378/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 379/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 380/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 381/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 382/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 383/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 384/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 385/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 386/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 387/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 388/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 389/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 390/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 391/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 392/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 393/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 394/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 395/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 396/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 397/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 398/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 399/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 400/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 401/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 402/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 403/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 404/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 405/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 406/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 407/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 408/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 409/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 410/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 411/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 412/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 413/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 414/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 415/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 416/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 417/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 418/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 419/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 420/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 421/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 422/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 423/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 424/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 425/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 426/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 427/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 428/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 429/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 430/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 431/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 432/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 433/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 434/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 435/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 436/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 437/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 438/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 439/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 440/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 441/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 442/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 443/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 444/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 445/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 446/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 447/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 448/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 449/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 450/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 451/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 452/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 453/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 454/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 455/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 456/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 457/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 458/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 459/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 460/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 461/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 462/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 463/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 464/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 465/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 466/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 467/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 468/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 469/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 470/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 471/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 472/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 473/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 474/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 475/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 476/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 477/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 478/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 479/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 480/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 481/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 482/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 483/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 484/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 485/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 486/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 487/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 488/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 489/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 490/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 491/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 492/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 493/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 494/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 495/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 496/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 497/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 498/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 499/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 500/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 501/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 502/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 503/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 504/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 505/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 506/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 507/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 508/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 509/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 510/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 511/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 512/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 513/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 514/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 515/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 516/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 517/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 518/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 519/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 520/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 521/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 522/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 523/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 524/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 525/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 526/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 527/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 528/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 529/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 530/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 531/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 532/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 533/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 534/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 535/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 536/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 537/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 538/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 539/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 540/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 541/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 542/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 543/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 544/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 545/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 546/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 547/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 548/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 549/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 550/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 551/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 552/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 553/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 554/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 555/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 556/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 557/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 558/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 559/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 560/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 561/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 562/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 563/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 564/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 565/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 566/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 567/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 568/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 569/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 570/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 571/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 572/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 573/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 574/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 575/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 576/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 577/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 578/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 579/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 580/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 581/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 582/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 583/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 584/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 585/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 586/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 587/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 588/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 589/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 590/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 591/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 592/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 593/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 594/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 595/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 596/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 597/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 598/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 599/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 600/600\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.5065 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, \n",
    "                          validation_data=(X_test_norm, y_test), epochs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61f4275a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24319911850>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efacf9d0",
   "metadata": {},
   "source": [
    "- Note that this graph begins where the other left off.  \n",
    "- While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  \n",
    "- This suggests that our network will not benefit from further training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c70e1",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dd0c407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6497 - accuracy: 0.6493 - val_loss: 0.6341 - val_accuracy: 0.6719\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6493 - val_loss: 0.6326 - val_accuracy: 0.6719\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6510 - val_loss: 0.6311 - val_accuracy: 0.6719\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.6528 - val_loss: 0.6296 - val_accuracy: 0.6719\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6597 - val_loss: 0.6281 - val_accuracy: 0.6667\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6667 - val_loss: 0.6266 - val_accuracy: 0.6719\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6632 - val_loss: 0.6251 - val_accuracy: 0.6719\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6667 - val_loss: 0.6236 - val_accuracy: 0.6719\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6667 - val_loss: 0.6221 - val_accuracy: 0.6719\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6649 - val_loss: 0.6205 - val_accuracy: 0.6771\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6719 - val_loss: 0.6190 - val_accuracy: 0.6771\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6753 - val_loss: 0.6176 - val_accuracy: 0.6771\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6736 - val_loss: 0.6161 - val_accuracy: 0.6875\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6806 - val_loss: 0.6146 - val_accuracy: 0.6875\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6806 - val_loss: 0.6131 - val_accuracy: 0.6979\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6788 - val_loss: 0.6116 - val_accuracy: 0.6979\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6806 - val_loss: 0.6102 - val_accuracy: 0.6979\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.6823 - val_loss: 0.6087 - val_accuracy: 0.6979\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6840 - val_loss: 0.6073 - val_accuracy: 0.6979\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6840 - val_loss: 0.6058 - val_accuracy: 0.6979\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6840 - val_loss: 0.6043 - val_accuracy: 0.6979\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6858 - val_loss: 0.6029 - val_accuracy: 0.6979\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6858 - val_loss: 0.6014 - val_accuracy: 0.6979\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6858 - val_loss: 0.5999 - val_accuracy: 0.6979\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6875 - val_loss: 0.5985 - val_accuracy: 0.6979\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6892 - val_loss: 0.5971 - val_accuracy: 0.6979\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6892 - val_loss: 0.5957 - val_accuracy: 0.6979\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.6892 - val_loss: 0.5944 - val_accuracy: 0.6979\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6910 - val_loss: 0.5930 - val_accuracy: 0.7031\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6910 - val_loss: 0.5917 - val_accuracy: 0.7031\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.6910 - val_loss: 0.5904 - val_accuracy: 0.7031\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6910 - val_loss: 0.5891 - val_accuracy: 0.7031\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6892 - val_loss: 0.5878 - val_accuracy: 0.7031\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.6910 - val_loss: 0.5865 - val_accuracy: 0.7031\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6927 - val_loss: 0.5853 - val_accuracy: 0.7031\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6944 - val_loss: 0.5840 - val_accuracy: 0.7031\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6962 - val_loss: 0.5828 - val_accuracy: 0.7031\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.6979 - val_loss: 0.5816 - val_accuracy: 0.7031\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6997 - val_loss: 0.5804 - val_accuracy: 0.6979\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6997 - val_loss: 0.5793 - val_accuracy: 0.6979\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7014 - val_loss: 0.5781 - val_accuracy: 0.6979\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7031 - val_loss: 0.5770 - val_accuracy: 0.6979\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7031 - val_loss: 0.5759 - val_accuracy: 0.6979\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7049 - val_loss: 0.5748 - val_accuracy: 0.6979\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7049 - val_loss: 0.5737 - val_accuracy: 0.6979\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7049 - val_loss: 0.5726 - val_accuracy: 0.6979\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7031 - val_loss: 0.5715 - val_accuracy: 0.6979\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7066 - val_loss: 0.5705 - val_accuracy: 0.6979\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7066 - val_loss: 0.5694 - val_accuracy: 0.7031\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7066 - val_loss: 0.5684 - val_accuracy: 0.7031\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7049 - val_loss: 0.5674 - val_accuracy: 0.7031\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7066 - val_loss: 0.5664 - val_accuracy: 0.7031\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7066 - val_loss: 0.5653 - val_accuracy: 0.7031\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7066 - val_loss: 0.5643 - val_accuracy: 0.7031\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7101 - val_loss: 0.5633 - val_accuracy: 0.7031\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7101 - val_loss: 0.5624 - val_accuracy: 0.7031\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7118 - val_loss: 0.5614 - val_accuracy: 0.7031\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7118 - val_loss: 0.5604 - val_accuracy: 0.7031\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7135 - val_loss: 0.5594 - val_accuracy: 0.7031\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7153 - val_loss: 0.5585 - val_accuracy: 0.7031\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7170 - val_loss: 0.5576 - val_accuracy: 0.7083\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7170 - val_loss: 0.5567 - val_accuracy: 0.7083\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7170 - val_loss: 0.5558 - val_accuracy: 0.7083\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7170 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7135 - val_loss: 0.5539 - val_accuracy: 0.7083\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7135 - val_loss: 0.5530 - val_accuracy: 0.7083\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7153 - val_loss: 0.5521 - val_accuracy: 0.7083\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7153 - val_loss: 0.5512 - val_accuracy: 0.7083\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7135 - val_loss: 0.5504 - val_accuracy: 0.7083\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7153 - val_loss: 0.5495 - val_accuracy: 0.7083\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7153 - val_loss: 0.5487 - val_accuracy: 0.7083\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7188 - val_loss: 0.5479 - val_accuracy: 0.7135\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7222 - val_loss: 0.5471 - val_accuracy: 0.7083\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7240 - val_loss: 0.5463 - val_accuracy: 0.7031\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7240 - val_loss: 0.5455 - val_accuracy: 0.7031\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7240 - val_loss: 0.5447 - val_accuracy: 0.7083\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7222 - val_loss: 0.5439 - val_accuracy: 0.7083\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7240 - val_loss: 0.5431 - val_accuracy: 0.7031\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7257 - val_loss: 0.5424 - val_accuracy: 0.7083\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7257 - val_loss: 0.5416 - val_accuracy: 0.7135\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7257 - val_loss: 0.5409 - val_accuracy: 0.7188\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7257 - val_loss: 0.5401 - val_accuracy: 0.7188\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7257 - val_loss: 0.5394 - val_accuracy: 0.7188\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7257 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7257 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7274 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7274 - val_loss: 0.5367 - val_accuracy: 0.7135\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7274 - val_loss: 0.5361 - val_accuracy: 0.7135\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7257 - val_loss: 0.5354 - val_accuracy: 0.7135\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7274 - val_loss: 0.5348 - val_accuracy: 0.7135\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7274 - val_loss: 0.5342 - val_accuracy: 0.7135\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7274 - val_loss: 0.5336 - val_accuracy: 0.7188\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7257 - val_loss: 0.5330 - val_accuracy: 0.7240\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7257 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7257 - val_loss: 0.5318 - val_accuracy: 0.7292\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7274 - val_loss: 0.5312 - val_accuracy: 0.7292\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7292 - val_loss: 0.5307 - val_accuracy: 0.7292\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7292 - val_loss: 0.5301 - val_accuracy: 0.7344\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7292 - val_loss: 0.5296 - val_accuracy: 0.7344\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7292 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7292 - val_loss: 0.5286 - val_accuracy: 0.7344\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7292 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7292 - val_loss: 0.5276 - val_accuracy: 0.7344\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7309 - val_loss: 0.5271 - val_accuracy: 0.7344\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7309 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7326 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7344 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7344 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7344 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7344 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7344 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7361 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7344 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7344 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7361 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7413 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7413 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7413 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7344\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7465 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7465 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7465 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7483 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7500 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7517 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7517 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7517 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7517 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7517 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7517 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7500 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7500 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7500 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7500 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7500 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7517 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7500 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7500 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7517 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7517 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7500 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7500 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7483 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7500 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7500 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7500 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7517 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7517 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7535 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7517 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7517 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7500 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7500 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7500 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7500 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7465 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7552 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7535 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7535 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7535 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7552 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7552 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7535 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7552 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7552 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7552 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7552 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7535 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7535 - val_loss: 0.5129 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7535 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7517 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7500 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7517 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7517 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7517 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7517 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7517 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7535 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7552 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7552 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7569 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7569 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7552 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7552 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7535 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7552 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7569 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7552 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7569 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7569 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7587 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7569 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7587 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7587 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7587 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7569 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7569 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7569 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7587 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7569 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7569 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7552 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7552 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7552 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7552 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7535 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7552 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7552 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7552 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7552 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7569 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7552 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7587 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7587 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7587 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7587 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7587 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7587 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7587 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7587 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7569 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7569 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7587 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7569 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7622 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7622 - val_loss: 0.5157 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7622 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7639 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7639 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7656 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7656 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7656 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7656 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7656 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7656 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7674 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7674 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7674 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7674 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7674 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7674 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7674 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7674 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7674 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7674 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7674 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7674 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7674 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7639 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7656 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7656 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7656 - val_loss: 0.5182 - val_accuracy: 0.7448\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7656 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7674 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7674 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7674 - val_loss: 0.5186 - val_accuracy: 0.7448\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7656 - val_loss: 0.5186 - val_accuracy: 0.7448\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7674 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7656 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7656 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7656 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7656 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7656 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7656 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7656 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7656 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7656 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7656 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7674 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7674 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7674 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7674 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7674 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7691 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7691 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7691 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7708 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7708 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7708 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7691 - val_loss: 0.5207 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7674 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7691 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7726 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7708 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7726 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7708 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7708 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7708 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7726 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7708 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7708 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7726 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7726 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7726 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7726 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7726 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7726 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7743 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7726 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7726 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7726 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7726 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7726 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7726 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7726 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7726 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7760 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7743 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7743 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7760 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7743 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7795 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7778 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7778 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7795 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7778 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7778 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7795 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7778 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7778 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7795 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7795 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7795 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7795 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7795 - val_loss: 0.5249 - val_accuracy: 0.7604\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7604\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7812 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7812 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7795 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7812 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7604\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7778 - val_loss: 0.5252 - val_accuracy: 0.7604\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7812 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7812 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7795 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7795 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7812 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7812 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7795 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7812 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7812 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7812 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7812 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7812 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7812 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5267 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.5270 - val_accuracy: 0.7552\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.5271 - val_accuracy: 0.7552\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7552\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7552\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.5273 - val_accuracy: 0.7552\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.5274 - val_accuracy: 0.7552\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7830 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5276 - val_accuracy: 0.7552\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5277 - val_accuracy: 0.7552\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5277 - val_accuracy: 0.7552\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7830 - val_loss: 0.5278 - val_accuracy: 0.7552\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7830 - val_loss: 0.5278 - val_accuracy: 0.7552\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7830 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7830 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7830 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7830 - val_loss: 0.5281 - val_accuracy: 0.7500\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7830 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7830 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7865 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7865 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.5305 - val_accuracy: 0.7396\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7865 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.5313 - val_accuracy: 0.7396\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7882 - val_loss: 0.5313 - val_accuracy: 0.7396\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7882 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7882 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7882 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7882 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7917 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7917 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7917 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7917 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7917 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7917 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7917 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7917 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7917 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5350 - val_accuracy: 0.7396\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5350 - val_accuracy: 0.7396\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.5351 - val_accuracy: 0.7396\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7396\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5351 - val_accuracy: 0.7396\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5352 - val_accuracy: 0.7396\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5352 - val_accuracy: 0.7396\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7396\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5354 - val_accuracy: 0.7396\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.5354 - val_accuracy: 0.7396\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.5354 - val_accuracy: 0.7396\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5355 - val_accuracy: 0.7396\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.5355 - val_accuracy: 0.7396\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.5356 - val_accuracy: 0.7396\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.5356 - val_accuracy: 0.7396\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.5357 - val_accuracy: 0.7396\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7396\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.5357 - val_accuracy: 0.7396\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.5358 - val_accuracy: 0.7396\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.5358 - val_accuracy: 0.7396\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7917 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7917 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.5363 - val_accuracy: 0.7396\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.5363 - val_accuracy: 0.7396\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.5364 - val_accuracy: 0.7396\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.5364 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.5365 - val_accuracy: 0.7396\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.5365 - val_accuracy: 0.7396\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.5366 - val_accuracy: 0.7396\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.5366 - val_accuracy: 0.7396\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.5367 - val_accuracy: 0.7396\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.5367 - val_accuracy: 0.7396\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7951 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.5373 - val_accuracy: 0.7448\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7951 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7951 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7951 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7951 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7934 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7934 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7934 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7934 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7934 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7934 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7934 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7934 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7934 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7934 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7934 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7934 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7934 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7934 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5398 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.5420 - val_accuracy: 0.7500\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.5420 - val_accuracy: 0.7500\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5420 - val_accuracy: 0.7500\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5420 - val_accuracy: 0.7500\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.5421 - val_accuracy: 0.7500\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.5421 - val_accuracy: 0.7500\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.5421 - val_accuracy: 0.7500\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.5421 - val_accuracy: 0.7500\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7951 - val_loss: 0.5422 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7951 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7951 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7951 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7951 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7934 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7951 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7951 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7934 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7934 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7934 - val_loss: 0.5428 - val_accuracy: 0.7500\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7917 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7917 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7934 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7917 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7917 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7917 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7917 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7917 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7917 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7917 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7917 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7917 - val_loss: 0.5430 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7917 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7917 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7917 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7934 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7934 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7899 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7899 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5437 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5438 - val_accuracy: 0.7448\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.5440 - val_accuracy: 0.7448\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5441 - val_accuracy: 0.7448\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5441 - val_accuracy: 0.7448\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5442 - val_accuracy: 0.7448\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5442 - val_accuracy: 0.7448\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5442 - val_accuracy: 0.7448\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5443 - val_accuracy: 0.7448\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5443 - val_accuracy: 0.7448\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5448 - val_accuracy: 0.7396\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5448 - val_accuracy: 0.7396\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5457 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5461 - val_accuracy: 0.7396\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5466 - val_accuracy: 0.7344\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5466 - val_accuracy: 0.7344\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5466 - val_accuracy: 0.7344\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5466 - val_accuracy: 0.7344\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7917 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5474 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5474 - val_accuracy: 0.7344\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5474 - val_accuracy: 0.7344\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5474 - val_accuracy: 0.7344\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7917 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7344\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5498 - val_accuracy: 0.7292\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5498 - val_accuracy: 0.7292\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7986 - val_loss: 0.5498 - val_accuracy: 0.7292\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5498 - val_accuracy: 0.7292\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.5499 - val_accuracy: 0.7292\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5499 - val_accuracy: 0.7292\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5499 - val_accuracy: 0.7292\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5499 - val_accuracy: 0.7292\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5499 - val_accuracy: 0.7292\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5500 - val_accuracy: 0.7292\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5500 - val_accuracy: 0.7292\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5500 - val_accuracy: 0.7292\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5500 - val_accuracy: 0.7292\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5500 - val_accuracy: 0.7292\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.5502 - val_accuracy: 0.7292\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5502 - val_accuracy: 0.7344\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5502 - val_accuracy: 0.7344\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5502 - val_accuracy: 0.7344\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5502 - val_accuracy: 0.7344\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5502 - val_accuracy: 0.7344\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5502 - val_accuracy: 0.7344\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8003 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8003 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8003 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5511 - val_accuracy: 0.7344\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5512 - val_accuracy: 0.7344\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5512 - val_accuracy: 0.7344\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5512 - val_accuracy: 0.7344\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5513 - val_accuracy: 0.7344\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5513 - val_accuracy: 0.7344\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.5513 - val_accuracy: 0.7344\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.5513 - val_accuracy: 0.7344\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.5514 - val_accuracy: 0.7344\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.5514 - val_accuracy: 0.7344\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5514 - val_accuracy: 0.7344\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.5517 - val_accuracy: 0.7344\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.5517 - val_accuracy: 0.7344\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7986 - val_loss: 0.5517 - val_accuracy: 0.7344\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5517 - val_accuracy: 0.7344\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7986 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5520 - val_accuracy: 0.7344\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5520 - val_accuracy: 0.7344\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5520 - val_accuracy: 0.7344\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.5520 - val_accuracy: 0.7344\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.5521 - val_accuracy: 0.7344\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.5521 - val_accuracy: 0.7344\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.5521 - val_accuracy: 0.7344\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5521 - val_accuracy: 0.7344\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5524 - val_accuracy: 0.7344\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.5524 - val_accuracy: 0.7344\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.5524 - val_accuracy: 0.7344\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.5524 - val_accuracy: 0.7344\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8038 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8021 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5530 - val_accuracy: 0.7344\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5530 - val_accuracy: 0.7344\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5530 - val_accuracy: 0.7344\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5530 - val_accuracy: 0.7292\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8038 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5531 - val_accuracy: 0.7292\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8021 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8021 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5536 - val_accuracy: 0.7188\n"
     ]
    }
   ],
   "source": [
    "model_2 = tf.keras.Sequential()\n",
    "model_2.add(tf.keras.layers.Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(tf.keras.layers.Dense(6, activation=\"relu\"))\n",
    "model_2.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, \n",
    "                         validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b6aeda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51b9eef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "970d1d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.719\n",
      "Roc-Auc is: 0.791\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "\n",
    "print(f\"Accuracy is: {accuracy_score(y_test, y_pred_class_nn_2):.3f}\")\n",
    "print(f\"Roc-Auc is: {roc_auc_score(y_test, y_pred_prob_nn_2):.3f}\")\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c1241c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a7aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
