{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf50fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2f02c",
   "metadata": {},
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part g: Transfer Learning DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc97152",
   "metadata": {},
   "source": [
    "- For this exercise, we will use the well-known MNIST digit data. \n",
    "- To illustrate the power and concept of transfer learning, we will train a CNN on just the digits 5,6,7,8,9.  \n",
    "- Then we will train just the last layer(s) of the network on the digits 0,1,2,3,4 and see how well the features learned on 5-9 help with classifying 0-4.\n",
    "\n",
    "Adapted from https://github.com/fchollet/keras/blob/master/examples/mnist_transfer_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8cad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to help some of the timing functions\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce37711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "batch_size = 128\n",
    "num_classes = 5\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f073338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some more parameters\n",
    "img_rows, img_cols = 28, 28\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ffe23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To simplify things, write a function to include all the training steps\n",
    "## As input, function takes a model, training set, test set, and the number of classes\n",
    "## Inside the model object will be the state about which layers we are freezing and which we are training\n",
    "\n",
    "def train_model(model, train, test, num_classes):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_test = x_test.astype(\"float32\")\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"train samples: {x_train.shape[0]}\")\n",
    "    print(f\"test samples: {x_test.shape[0]}\")\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = tf.keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(test[1], num_classes)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adadelta()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    t = now()\n",
    "    model.fit(x_train, y_train, batch_size=batch_size,\n",
    "              epochs=epochs, verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print(f\"Training time: {now()-t}\")\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Test score: {score[0]}\")\n",
    "    print(f\"Test accuracy: {score[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb792a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8bfbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two datasets: one with digits below 5 and one with 5 and above\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eca4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"feature\" layers.  These are the early layers that we expect will \"transfer\"\n",
    "# to a new problem.  We will freeze these layers during the fine-tuning process\n",
    "\n",
    "\n",
    "feature_layers  =[\n",
    "    tf.keras.layers.Conv2D(filters, kernel_size, padding=\"valid\",\n",
    "                           input_shape=input_shape),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters, kernel_size),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=pool_size),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e83fbee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"classification\" layers.  These are the later layers that predict the specific classes from the features\n",
    "# learned by the feature layers.  This is the part of the model that needs to be re-trained for a new problem\n",
    "\n",
    "classification_layers = [\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes),\n",
    "    tf.keras.layers.Activation(\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2909269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our model by combining the two sets of layers as follows\n",
    "model = tf.keras.models.Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55f05f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 600,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e203d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "train samples: 29404\n",
      "test samples: 4861\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 1.6032 - accuracy: 0.2199 - val_loss: 1.5830 - val_accuracy: 0.2253\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 1.5743 - accuracy: 0.2821 - val_loss: 1.5526 - val_accuracy: 0.3228\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 1.5459 - accuracy: 0.3611 - val_loss: 1.5202 - val_accuracy: 0.5246\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 1.5156 - accuracy: 0.4328 - val_loss: 1.4843 - val_accuracy: 0.6468\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 1.4799 - accuracy: 0.5046 - val_loss: 1.4436 - val_accuracy: 0.7120\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 13s 56ms/step - loss: 1.4417 - accuracy: 0.5522 - val_loss: 1.3976 - val_accuracy: 0.7472\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 1.3986 - accuracy: 0.5944 - val_loss: 1.3458 - val_accuracy: 0.7698\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 1.3473 - accuracy: 0.6288 - val_loss: 1.2876 - val_accuracy: 0.7865\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 13s 55ms/step - loss: 1.2942 - accuracy: 0.6575 - val_loss: 1.2236 - val_accuracy: 0.7996\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 13s 57ms/step - loss: 1.2336 - accuracy: 0.6809 - val_loss: 1.1553 - val_accuracy: 0.8132\n",
      "Training time: 0:02:08.558053\n",
      "Test score: 1.1552823781967163\n",
      "Test accuracy: 0.8132071495056152\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train our model on the digits 5,6,7,8,9\n",
    "train_model(model,\n",
    "           (x_train_gte5, y_train_gte5),\n",
    "           (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a283839",
   "metadata": {},
   "source": [
    "### Freezing Layers\n",
    "- Keras allows layers to be \"frozen\" during the training process.\n",
    "- That is, some layers would have their weights updated during the training process, while others would not.\n",
    "- This is a core part of transfer learning, the ability to train just the last one or several layers.\n",
    "<br>\n",
    "- Note also, that a lot of the training time is spent \"back-propagating\" the gradients back to the first layer.  \n",
    "- Therefore, if we only need to compute the gradients back a small number of layers, the training time is much quicker per iteration.\n",
    "- This is in addition to the savings gained by being able to train on a smaller data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96830dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a20dd90",
   "metadata": {},
   "source": [
    "Observe below the differences between the number of **total params**, **trainable params**, and **non-trainable params**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f4fd87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 590,597\n",
      "Non-trainable params: 9,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a79439d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "train samples: 30596\n",
      "test samples: 5139\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 18ms/step - loss: 1.5550 - accuracy: 0.3390 - val_loss: 1.4929 - val_accuracy: 0.4581\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 1.4802 - accuracy: 0.4048 - val_loss: 1.4152 - val_accuracy: 0.5353\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 1.4109 - accuracy: 0.4699 - val_loss: 1.3428 - val_accuracy: 0.6231\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 1.3478 - accuracy: 0.5346 - val_loss: 1.2753 - val_accuracy: 0.7017\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 4s 17ms/step - loss: 1.2855 - accuracy: 0.5951 - val_loss: 1.2107 - val_accuracy: 0.7605\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 4s 17ms/step - loss: 1.2279 - accuracy: 0.6469 - val_loss: 1.1496 - val_accuracy: 0.8054\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 4s 17ms/step - loss: 1.1730 - accuracy: 0.6923 - val_loss: 1.0925 - val_accuracy: 0.8348\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 4s 17ms/step - loss: 1.1189 - accuracy: 0.7358 - val_loss: 1.0372 - val_accuracy: 0.8558\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 4s 17ms/step - loss: 1.0698 - accuracy: 0.7634 - val_loss: 0.9854 - val_accuracy: 0.8720\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 4s 17ms/step - loss: 1.0197 - accuracy: 0.7886 - val_loss: 0.9363 - val_accuracy: 0.8838\n",
      "Training time: 0:00:42.704128\n",
      "Test score: 0.9363081455230713\n",
      "Test accuracy: 0.8838295340538025\n"
     ]
    }
   ],
   "source": [
    "train_model(model,\n",
    "           (x_train_lt5, y_train_lt5),\n",
    "           (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2af106",
   "metadata": {},
   "source": [
    "- Note that after a single epoch, we are already achieving results on classifying 0-4 that are comparable to those achieved on 5-9 after 5 full epochs.\n",
    "- This despite the fact the we are only \"fine-tuning\" the last layer of the network, and all the early layers have never seen what the digits 0-4 look like.\n",
    "\n",
    "- Also, note that even though nearly all (590K/600K) of the *parameters* were trainable, **the training time per epoch was still much reduced.**  \n",
    "- **This is because the unfrozen part of the network was very shallow, making backpropagation faster.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ddbfd",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "- Now we will write code to reverse this training process.  That is, train on the digits 0-4, then finetune only the last layers on the digits 5-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073176f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 600,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create layers and define the model as above\n",
    "feature_layers2 = [\n",
    "    tf.keras.layers.Conv2D(filters, kernel_size,\n",
    "                           padding=\"valid\",\n",
    "                           input_shape=input_shape),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters, kernel_size),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=pool_size),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten()\n",
    "]\n",
    "\n",
    "classification_layers2 = [\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes),\n",
    "    tf.keras.layers.Activation(\"softmax\")\n",
    "]\n",
    "\n",
    "model2 = tf.keras.models.Sequential(feature_layers2 + classification_layers2)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "257ec0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "train samples: 30596\n",
      "test samples: 5139\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 14s 54ms/step - loss: 1.6094 - accuracy: 0.2051 - val_loss: 1.5838 - val_accuracy: 0.2716\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 1.5752 - accuracy: 0.2845 - val_loss: 1.5470 - val_accuracy: 0.4585\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 1.5396 - accuracy: 0.3656 - val_loss: 1.5067 - val_accuracy: 0.5882\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 1.4993 - accuracy: 0.4549 - val_loss: 1.4607 - val_accuracy: 0.7143\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 1.4540 - accuracy: 0.5366 - val_loss: 1.4068 - val_accuracy: 0.8060\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 1.3998 - accuracy: 0.6067 - val_loss: 1.3429 - val_accuracy: 0.8476\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 1.3353 - accuracy: 0.6730 - val_loss: 1.2686 - val_accuracy: 0.8714\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 1.2641 - accuracy: 0.7211 - val_loss: 1.1836 - val_accuracy: 0.8856\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 1.1843 - accuracy: 0.7602 - val_loss: 1.0899 - val_accuracy: 0.9002\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 1.0959 - accuracy: 0.7886 - val_loss: 0.9879 - val_accuracy: 0.9103\n",
      "Training time: 0:02:13.304936\n",
      "Test score: 0.9878644943237305\n",
      "Test accuracy: 0.9102938175201416\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train our model on the digits 0,1,2,3,4\n",
    "train_model(model2,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96858e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze layers\n",
    "for l in feature_layers2:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fed43a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 590,597\n",
      "Non-trainable params: 9,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e5765aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "train samples: 29404\n",
      "test samples: 4861\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.6053 - accuracy: 0.3025 - val_loss: 1.5367 - val_accuracy: 0.3750\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.5351 - accuracy: 0.3380 - val_loss: 1.4706 - val_accuracy: 0.4232\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.4748 - accuracy: 0.3821 - val_loss: 1.4092 - val_accuracy: 0.4871\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.4185 - accuracy: 0.4347 - val_loss: 1.3510 - val_accuracy: 0.5688\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.3682 - accuracy: 0.4856 - val_loss: 1.2960 - val_accuracy: 0.6336\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.3176 - accuracy: 0.5362 - val_loss: 1.2440 - val_accuracy: 0.6892\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.2665 - accuracy: 0.5881 - val_loss: 1.1947 - val_accuracy: 0.7254\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.2228 - accuracy: 0.6266 - val_loss: 1.1481 - val_accuracy: 0.7535\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.1800 - accuracy: 0.6606 - val_loss: 1.1042 - val_accuracy: 0.7768\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 1.1401 - accuracy: 0.6832 - val_loss: 1.0625 - val_accuracy: 0.7986\n",
      "Training time: 0:00:39.412123\n",
      "Test score: 1.0624998807907104\n",
      "Test accuracy: 0.7986010909080505\n"
     ]
    }
   ],
   "source": [
    "train_model(model2,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7a494",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8761782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
